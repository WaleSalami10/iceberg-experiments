{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec68ae14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.jars': 's3://vasveena-test-demo/jars/iceberg-spark3-runtime-0.11.1.jar', 'spark.sql.extensions': 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions', 'spark.sql.catalog.spark_catalog': 'org.apache.iceberg.spark.SparkSessionCatalog', 'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.sql.catalog.local': 'org.apache.iceberg.spark.SparkCatalog', 'spark.sql.catalog.local.type': 'hadoop', 'spark.sql.catalog.local.warehouse': 's3://vasveena-test-demo/iceberg/catalog/tables/'}, 'proxyUser': 'user_vasveena', 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":  { \n",
    "             \"spark.jars\":\"s3://vasveena-test-demo/jars/iceberg-spark3-runtime-0.11.1.jar\",\n",
    "             \"spark.sql.extensions\":\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\",\n",
    "             \"spark.sql.catalog.spark_catalog\":\"org.apache.iceberg.spark.SparkSessionCatalog\",\n",
    "             \"spark.sql.catalog.spark_catalog.type\":\"hive\",\n",
    "             \"spark.sql.catalog.local\":\"org.apache.iceberg.spark.SparkCatalog\",\n",
    "             \"spark.sql.catalog.local.type\":\"hadoop\",\n",
    "             \"spark.sql.catalog.local.warehouse\":\"s3://vasveena-test-demo/iceberg/catalog/tables/\"\n",
    "           } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1c1af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd16670e1e94284acb3ffd1ce4c9e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1629139174081_0036</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-37-140.ec2.internal:20888/proxy/application_1629139174081_0036/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-34-112.ec2.internal:8042/node/containerlogs/container_1629139174081_0036_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_df: org.apache.spark.sql.DataFrame = [id: bigint, month: bigint ... 5 more fields]\n",
      "res1: Long = 100000000\n"
     ]
    }
   ],
   "source": [
    "val input_df = spark.read.parquet(\"s3://neilawstmp2/tmp/hudi-perf/input/\")\n",
    "input_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63bc6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bfb1f2e67c457e85be389a053f53c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_df2: org.apache.spark.sql.DataFrame = [id: bigint, month: bigint ... 9 more fields]\n",
      "+-------+-----+-------+---+--------------------+----+-------------------+---+--------+------+----------+\n",
      "|     id|month|     sk|txt|                uuid|year| modified_timestamp|  z|schema-v|data-v|  trade_dt|\n",
      "+-------+-----+-------+---+--------------------+----+-------------------+---+--------+------+----------+\n",
      "|4000000|    3|4000000|[E]|6e505939-f5fd-4ab...|2019|2021-04-02 00:05:02|  9|      v1|    v2|2021-04-02|\n",
      "|4000001|    9|4000001|[F]|20486aca-2759-43f...|2019|2021-04-02 00:05:02|  d|      v1|    v2|2021-04-02|\n",
      "|4000002|   11|4000002|[G]|42962a21-a2dc-40d...|2019|2021-04-02 00:05:02|  d|      v1|    v2|2021-04-02|\n",
      "|4000003|    9|4000003|[H]|9841ad6d-1532-496...|2019|2021-04-02 00:05:02|  c|      v1|    v2|2021-04-02|\n",
      "|4000004|    4|4000004|[I]|ff1a855a-cced-495...|2019|2021-04-02 00:05:02|  4|      v1|    v2|2021-04-02|\n",
      "+-------+-----+-------+---+--------------------+----+-------------------+---+--------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "input_df4: org.apache.spark.sql.DataFrame = [id: bigint, month: bigint ... 9 more fields]\n",
      "warning: there was one deprecation warning (since 2.0.0); for details, enable `:setting -deprecation' or `:replay -deprecation'\n"
     ]
    }
   ],
   "source": [
    "val input_df2=(input_df.withColumn(\"z\", substring(md5(concat($\"id\")),1,1))\n",
    ".withColumn(\"schema-v\", lit(\"v1\")).withColumn(\"data-v\", lit(\"v2\"))\n",
    ".withColumn(\"trade_dt\", substring($\"modified_timestamp\",1,10)))\n",
    "input_df2.show(5)\n",
    "\n",
    "val input_df4 = input_df2.withColumnRenamed(\"schema-v\", \"schema_v\").withColumnRenamed(\"data-v\", \"data_v\")\n",
    "\n",
    "input_df4.registerTempTable(\"inputdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fff108b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d500590546d94effa2b0ea1707859c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res18: org.apache.spark.sql.DataFrame = []\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE local.db.iceberg_table_sparksqldf26 (id bigint,\n",
    "                                       month bigint,\n",
    "                                       sk bigint,\n",
    "                                       txt struct<key1:string>,\n",
    "                                       uuid string,\n",
    "                                       year string,\n",
    "                                       modified_timestamp timestamp,\n",
    "                                       z string,\n",
    "                                       schema_v string,\n",
    "                                       data_v string,\n",
    "                                       trade_dt string)\n",
    "USING iceberg\n",
    "OPTIONS ( 'write.object-storage.enabled'=true,\n",
    "          'write.target-file-size-bytes'=20971520,\n",
    "          'write.parquet.row-group-size-bytes'=20971520,\n",
    "          'write.object-storage.path'='s3://vasveena-test-hmswh/')\n",
    "PARTITIONED BY (z,schema_v,data_v,trade_dt)\n",
    "location  's3://vasveena-test-demo/iceberg/catalog/tables/db/iceberg_table_sparksqldf26'\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51d219d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018c7fed83db4fffaff658f45b5f4b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table db.iceberg_table_sparksqldf26 not found;\n",
      "  at org.apache.spark.sql.execution.datasources.v2.DropTableExec.run(DropTableExec.scala:35)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)\n",
      "  at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:45)\n",
      "  at org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:230)\n",
      "  at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3667)\n",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.executeQuery$1(SQLExecution.scala:107)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:132)\n",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:104)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withTracker(SQLExecution.scala:227)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:132)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:131)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:68)\n",
      "  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3665)\n",
      "  at org.apache.spark.sql.Dataset.<init>(Dataset.scala:230)\n",
      "  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:98)\n",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:607)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:602)\n",
      "  ... 51 elided\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"drop table local.db.iceberg_table_sparksqldf26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "857f0180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ff016516c245b0850beeffe019a3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: Long = 305607782109057\n",
      "duration: String = 130.181471962seconds\n"
     ]
    }
   ],
   "source": [
    "val t1 = System.nanoTime\n",
    "\n",
    "//order by clause is needed to avoid error \"Caused by: java.lang.IllegalStateException: Already closed files for partition: z=c/schema_v=v1/data_v=v2/trade_dt=2021-04-02\"\n",
    "input_df4.orderBy(\"z\",\"`schema-v`\",\"`data-v`\",\"trade_dt\").write.mode(\"overwrite\").insertInto(\"local.db.iceberg_table_sparksqldf26\")\n",
    "\n",
    "val duration = (System.nanoTime - t1) / 1e9d + \"seconds\"\n",
    "\n",
    "//check S3 listing in file hmswhl_parqrowgroupsizeandtargetsize for this test where both\n",
    "// write.target-file-size-bytes and write.parquet.row-group-size-bytes were set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88965258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c9ebeb37f004d7a95013d915779cdb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.sql.functions._\n",
      "df: org.apache.spark.sql.DataFrame = [id: bigint, month: bigint ... 9 more fields]\n",
      "+--------------+\n",
      "|distinctCounts|\n",
      "+--------------+\n",
      "|16            |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "val df = spark.table(\"local.db.iceberg_table_sparksqldf26\")\n",
    "df.agg(countDistinct(\"z\", \"schema_v\",\"data_v\",\"trade_dt\").as(\"distinctCounts\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2e2d6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b3e041ae5a4d6f8deba6f27e4b0358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res85: org.apache.spark.sql.DataFrame = []\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE local.db.iceberg_table_sparksqldf22 (id bigint,\n",
    "                                       month bigint,\n",
    "                                       sk bigint,\n",
    "                                       txt struct<key1:string>,\n",
    "                                       uuid string,\n",
    "                                       year string,\n",
    "                                       modified_timestamp timestamp,\n",
    "                                       z string,\n",
    "                                       schema_v string,\n",
    "                                       data_v string,\n",
    "                                       trade_dt string)\n",
    "USING iceberg\n",
    "OPTIONS ( 'write.object-storage.enabled'=true,\n",
    "          --'write.target-file-size-bytes'=20971520,\n",
    "          --'write.parquet.row-group-size-bytes'=20971520,\n",
    "          'write.object-storage.path'='s3://vasveena-test-hmswh/')\n",
    "PARTITIONED BY (z,schema_v,data_v,trade_dt)\n",
    "location  's3://vasveena-test-demo/iceberg/catalog/tables/db/iceberg_table_sparksqldf22'\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34c8977c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3f3dcd2b5b4d8698e080e4609bfdab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: Long = 299631140646338\n",
      "duration: String = 117.399936972seconds\n"
     ]
    }
   ],
   "source": [
    "val t1 = System.nanoTime\n",
    "\n",
    "//order by clause is needed to avoid error \"Caused by: java.lang.IllegalStateException: Already closed files for partition: z=c/schema_v=v1/data_v=v2/trade_dt=2021-04-02\"\n",
    "input_df4.orderBy(\"z\",\"`schema-v`\",\"`data-v`\",\"trade_dt\").write.mode(\"overwrite\").insertInto(\"local.db.iceberg_table_sparksqldf22\")\n",
    "\n",
    "val duration = (System.nanoTime - t1) / 1e9d + \"seconds\"\n",
    "\n",
    "//check S3 listing in file hmswhl_default for this test where \n",
    "//neither write.target-file-size-bytes nor write.parquet.row-group-size-bytes were set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c08bf264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34c57947d1441679d8cae30abaf9632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res84: org.apache.spark.sql.DataFrame = []\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"drop table local.db.iceberg_table_sparksqldf22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "416ff218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3096131f87714e88a274d05a31ccdd3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res56: org.apache.spark.sql.DataFrame = []\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE local.db.iceberg_table_sparksqldf24 (id bigint,\n",
    "                                       month bigint,\n",
    "                                       sk bigint,\n",
    "                                       txt struct<key1:string>,\n",
    "                                       uuid string,\n",
    "                                       year string,\n",
    "                                       modified_timestamp timestamp,\n",
    "                                       z string,\n",
    "                                       schema_v string,\n",
    "                                       data_v string,\n",
    "                                       trade_dt string)\n",
    "USING iceberg\n",
    "OPTIONS ( 'write.object-storage.enabled'=true,\n",
    "          --'write.target-file-size-bytes'=20971520,\n",
    "          'write.parquet.row-group-size-bytes'=20971520,\n",
    "          'write.object-storage.path'='s3://vasveena-test-hmswh/')\n",
    "PARTITIONED BY (z,schema_v,data_v,trade_dt)\n",
    "location  's3://vasveena-test-demo/iceberg/catalog/tables/db/iceberg_table_sparksqldf24'\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45659253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c6f3a70af54bbebe6c541a0259fae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: Long = 299957707048795\n",
      "duration: String = 113.369165187seconds\n"
     ]
    }
   ],
   "source": [
    "val t1 = System.nanoTime\n",
    "\n",
    "//order by clause is needed to avoid error \"Caused by: java.lang.IllegalStateException: Already closed files for partition: z=c/schema_v=v1/data_v=v2/trade_dt=2021-04-02\"\n",
    "input_df4.orderBy(\"z\",\"`schema-v`\",\"`data-v`\",\"trade_dt\").write.mode(\"overwrite\").insertInto(\"local.db.iceberg_table_sparksqldf24\")\n",
    "\n",
    "val duration = (System.nanoTime - t1) / 1e9d + \"seconds\"\n",
    "\n",
    "//check S3 listing in file hmswhl_parqrowgroupsizeonly for this test setting only write.parquet.row-group-size-bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17afe4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9e37210cc74a94aacd15c25c079ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res61: org.apache.spark.sql.DataFrame = []\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE local.db.iceberg_table_sparksqldf28 (id bigint,\n",
    "                                       month bigint,\n",
    "                                       sk bigint,\n",
    "                                       txt struct<key1:string>,\n",
    "                                       uuid string,\n",
    "                                       year string,\n",
    "                                       modified_timestamp timestamp,\n",
    "                                       z string,\n",
    "                                       schema_v string,\n",
    "                                       data_v string,\n",
    "                                       trade_dt string)\n",
    "USING iceberg\n",
    "OPTIONS ( 'write.object-storage.enabled'=true,\n",
    "          'write.target-file-size-bytes'=20971520,\n",
    "          --'write.parquet.row-group-size-bytes'=20971520,\n",
    "          'write.object-storage.path'='s3://vasveena-test-hmswh/')\n",
    "PARTITIONED BY (z,schema_v,data_v,trade_dt)\n",
    "location  's3://vasveena-test-demo/iceberg/catalog/tables/db/iceberg_table_sparksqldf28'\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5cec0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c585ffe12a4e73b4c61e7362affb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: Long = 300435418324943\n",
      "duration: String = 116.956403467seconds\n"
     ]
    }
   ],
   "source": [
    "val t1 = System.nanoTime\n",
    "\n",
    "//order by clause is needed to avoid error \"Caused by: java.lang.IllegalStateException: Already closed files for partition: z=c/schema_v=v1/data_v=v2/trade_dt=2021-04-02\"\n",
    "input_df4.orderBy(\"z\",\"`schema-v`\",\"`data-v`\",\"trade_dt\").write.mode(\"overwrite\").insertInto(\"local.db.iceberg_table_sparksqldf28\")\n",
    "\n",
    "val duration = (System.nanoTime - t1) / 1e9d + \"seconds\"\n",
    "\n",
    "//check S3 listing in file hmswhl_onlytargetsize for this test setting only write.target-file-size-bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d22dfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0feada02c5304e6e921689abe922c628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//dropped and recreated table local.db.iceberg_table_sparksqldf22 where neither of the target file size properties were set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48a0c3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75fe31ebb5745f791075c7c331da912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: Long = 302051274772223\n",
      "duration: String = 111.910471878seconds\n"
     ]
    }
   ],
   "source": [
    "//insert with repartition \n",
    "val t1 = System.nanoTime\n",
    "\n",
    "//order by clause is needed to avoid error \"Caused by: java.lang.IllegalStateException: Already closed files for partition: z=c/schema_v=v1/data_v=v2/trade_dt=2021-04-02\"\n",
    "input_df4.orderBy(\"z\",\"`schema-v`\",\"`data-v`\",\"trade_dt\").repartition(100).write.mode(\"overwrite\").insertInto(\"local.db.iceberg_table_sparksqldf22\")\n",
    "\n",
    "val duration = (System.nanoTime - t1) / 1e9d + \"seconds\"\n",
    "\n",
    "//check S3 listing in file hmswhl_repartition100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0d07a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c37bf93d4104c47a26e2614b4f1491d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//dropped and recreated table local.db.iceberg_table_sparksqldf26 where both target file size properties were set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa619d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62495b9c90334dd79200ad3e5ffaf037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1: Long = 305963713905968\n",
      "duration: String = 121.303479111seconds\n"
     ]
    }
   ],
   "source": [
    "//re-inserting with repartition\n",
    "\n",
    "val t1 = System.nanoTime\n",
    "\n",
    "//order by clause is needed to avoid error \"Caused by: java.lang.IllegalStateException: Already closed files for partition: z=c/schema_v=v1/data_v=v2/trade_dt=2021-04-02\"\n",
    "input_df4.orderBy(\"z\",\"`schema-v`\",\"`data-v`\",\"trade_dt\").repartition(100).write.mode(\"overwrite\").insertInto(\"local.db.iceberg_table_sparksqldf26\")\n",
    "\n",
    "val duration = (System.nanoTime - t1) / 1e9d + \"seconds\"\n",
    "\n",
    "//check S3 listing in file hmswhl_repartition100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20085559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4044c1489eee43e0b0ad056b71a54947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1633315542313_0024</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-66-109.ec2.internal:20888/proxy/application_1633315542313_0024/\" >Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-74-157.ec2.internal:8042/node/containerlogs/container_1633315542313_0024_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res1: String = 3.0.1-amzn-0\n"
     ]
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30181827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1384fb44dd7d46fcadfa9fdd5de45657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "org.apache.spark.sql.catalyst.parser.ParseException:\n",
      "extraneous input 'PURGE' expecting {<EOF>, ';'}(line 1, pos 112)\n",
      "\n",
      "== SQL ==\n",
      "delete from local.db.iceberg_table_sparksqldf24 where z=1 and schema_v=v1 and data_v=v2 and trade_dt=2021-04-04 PURGE\n",
      "----------------------------------------------------------------------------------------------------------------^^^\n",
      "\n",
      "  at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:266)\n",
      "  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parse(ParseDriver.scala:133)\n",
      "  at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:48)\n",
      "  at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(ParseDriver.scala:81)\n",
      "  at org.apache.spark.sql.catalyst.parser.extensions.IcebergSparkSqlExtensionsParser.parsePlan(IcebergSparkSqlExtensionsParser.scala:100)\n",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$2(SparkSession.scala:605)\n",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:149)\n",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:605)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:602)\n",
      "  ... 51 elided\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"delete from local.db.iceberg_table_sparksqldf24 where z=1 and schema_v=v1 and data_v=v2 and trade_dt=2021-04-04\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22696473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c74008415144296b845dac6fb0f51e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "org.apache.spark.sql.catalyst.parser.ParseException:\n",
      "extraneous input '(' expecting {'ADD', 'ALTER', 'AS', 'ASC', 'BY', 'CALL', 'DESC', 'DROP', 'FIELD', 'FIRST', 'LAST', 'NULLS', 'ORDERED', 'PARTITION', 'TABLE', 'WRITE', 'TRUE', 'FALSE', 'MAP', IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 69)\n",
      "\n",
      "== SQL ==\n",
      "alter table local.db.iceberg_table_sparksqldf24 drop partition field (z='1', schema_v='v1', data_v='v2', trade_dt='2021-04-02') PURGE\n",
      "---------------------------------------------------------------------^^^\n",
      "\n",
      "  at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(ParseDriver.scala:266)\n",
      "  at org.apache.spark.sql.catalyst.parser.extensions.IcebergSparkSqlExtensionsParser.parse(IcebergSparkSqlExtensionsParser.scala:145)\n",
      "  at org.apache.spark.sql.catalyst.parser.extensions.IcebergSparkSqlExtensionsParser.parsePlan(IcebergSparkSqlExtensionsParser.scala:98)\n",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$2(SparkSession.scala:605)\n",
      "  at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:149)\n",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:605)\n",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:764)\n",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:602)\n",
      "  ... 51 elided\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"alter table local.db.iceberg_table_sparksqldf24 drop partition field (z='1', schema_v='v1', data_v='v2', trade_dt='2021-04-02') PURGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALTER TABLE prod.db.sample DROP PARTITION FIELD shard "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
